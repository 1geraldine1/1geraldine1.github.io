---
title: "구글 FormNet과 이해를 위한 기반 지식 습득 - 1"
date: 2022-06-10T18:08:30-04:00
categories:
  - '2022-06 TIL'
tags:
  - '20220610'
  - 'TIL'
  - 'Google FormNet'
---

# 개요

* 조만간 있을것으로 예상되는 프로젝트의 주제를 찾기 위해 인터넷을 떠돌아 다니던 도중, 흥미로운 주제를 발견했다.

* Google에서 개발한 [FormNet](https://ai.googleblog.com/2022/04/formnet-beyond-sequential-modeling-for.html)이라는 양식화된 문서에 대한 인식 모델이다.

* 예전에 생각했던 아이디어중 하나로 ```제품 설명서를 OCR로 읽어들이고, 해당 내용을 챗봇으로 사용자와 소통하게 하면 어떨까?```라는것이 있었다.

  * 해당 계획을 진행하려다 말았던 가장 큰 이유중 하나가 <U>문서마다 다른 양식으로 인한 텍스트 정제 난이도 상승</U>이었는데, 구글의 연구진들은 어떤 방식을 썼을지 궁금해져 블로그 글을 작성해보기로 했다.

* 딥러닝 공부를 조금 한 편이기는 하지만, 석박사님들처럼 대학원에서 정식으로 배운것도 아니므로 상당히 많은 기초지식의 부재가 있을것으로 예상된다.

  * 따라서, 이 글 시리즈는 FormNet을 소개한 블로그 글의 이해와, 그 글의 이해를 위해 필요한 지식들을 공부하고, 그 결과를 수록하는 장이 될것으로 생각된다.

* 읽으며 추가적으로 지식이 필요해 별도로 정리한 경우에는 각주를 달아 별도로 정리해두려 한다.


## 본문 요약

### 기존 연구 및 기존 연구가 가진 한계점

* 시퀀스 모델링([Attention is All You Need](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)와 같은 모델들)은 자연어 처리 분야에서 최고 성능을 뽑아낼정도로 우수하다.

* 양식 문서(form document)에서 이러한 시퀀스 모델을 사용할때는 양식 문서를 직렬화(보통 왼쪽->오른쪽, 위->아래 방향으로)한 다음 시퀀스 모델을 적용하는 방식을 사용했다.

* 하지만 양식 문서에는 표, 열 등 다양한 레이아웃 구조가 존재한다.

* 이러한 다양한 레이아웃 구조는 직렬화를 어렵게 하고, 실질적인 성능을 감소시킨다.

### FormNet의 작동 방식 개요

* 따라서, 연구팀은 <B><U>단어 토큰간의 2D 공간 관계를 활용하는 Rich Attention 메커니즘</U></B>을 제시했다.

* GCN<sup>[[1]](#footnote_1)</sup>을 통해 인접한 토큰에 대해 의미있는 정보에 해당하는 Super-Tokens를 구성한다.

### 세부 작동방식 - FormNet

* 주어진 양식 문서를 OCR 및 BERT 엔진을 사용하여 단어를 식별하고 토큰화한다.

* 단어 토큰과 해당 토큰의 2D 좌표를 GCN에 입력한다.

* 스키마 학습을 위해 ETC(Extended Transformer Construction)레이어로 GCN으로 인코딩된 구조 인식 토큰을 처리함

* Viterbi 알고리즘<sup>[[2]](#footnote_2)</sup>을 사용하여 사후 확률을 최대화하는 시퀀스를 찾아냄.



<a name="footnote_1">[1]</a> : convolution layer의 feature를 이용한 업데이트 방식을 graph에 적용한 것으로, 각 노드의 인접노드들 정보를 이용해 노드를 갱신하는 방식을 의미한다.

<a name="footnote_2">[2]</a> : Hidden Markov Model의 사후 확률중 가장 높은것을 고르는 알고리즘. 

