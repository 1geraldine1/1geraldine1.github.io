---
title: "Dacon Daily Python Camp 1일차 공부"
date: 2021-11-11T18:30:00-04:00
categories:
  - '2021-11 TIL'
tags:
  - '20211111'
  - TIL
  - 의사결정나무
---


# Intro

* 프로젝트를 마무리한후, 스스로에게 잠깐 휴식을 준다는것이 생각보다 너무 길어져, 계획보다 너무 오래 쉬어버렸다.

  * 언제까지 퍼져있을수는 없으니 다시 1일 1업로드를 목표로 달려보기로 했다.

* 재활훈련을 위해 [dacon에서 제공하는 데이터분석 튜토리얼](https://dacon.io/competitions/open/235698/overview/description)을 진행해보기로 했다.

# TIL

## 데이터 체크

* ```DataFrame.isnull().sum()```으로 DataFrame의 각 열 별 결측치 수를 파악 가능

* ```DataFrame.info()```를 통해 DataFrame의 Non-Null Count, Dtype, memory usage를 파악 가능

## scikit-learn

* [scikit-learn 공식 홈페이지](https://scikit-learn.org/stable/)

  * scikit-learn에서 지원하는 모델들에 대한 종류들이 기록되어있다.

## 의사결정나무

* 의사 결정 규칙과 그 결과들을 트리 구조로 도식화한 의사 결정 지원 도구의 일종.

  * 스무고개로 생각하면 편함!

* 데이터들의 feature중 하나를 정해 해당 feature의 특정한 하나의 값을 정한다면, 이를 기준으로 모든 행들을 두개의 노드로 분할(decision rule, 이진분할)할수 있음.

* 파생된 노드들에 대해 같은 작업을 반복하며 모든 data가 피쳐의 값에 따라 분류됨.

* 특정한 값을 정하는 의사결정 나무의 대원칙은 <strong>"<U>한쪽방향으로 쏠리도록 하는것</U>"</strong>이다.

  * 피쳐의 값에 의해 분류될때는 공평하게 나누는것이 아닌, 한쪽 방향으로 쏠리도록 하는 피쳐의 값을 찾는것.

  * 이러한 피쳐의 값은 불순도(Impurity)와 향상도(Goodness of split)를 계산해 찾아냄.

* 가장 대표적인 의사결정나무인 ```CART 의사결정나무```는 이진분할을 사용

## CART 의사결정나무

* 관련 논문 : Breiman, Friedman, etc. 1984
* 이진분할 사용
* 연속형 변수 부등호 활용
* 범주형 변수 부분집합 활용
* 분할정복 알고리즘을 이용한 접근(Divide-and-conquer approach)
* 탐욕 알고리즘을 활용한 불순도 측정(Greedy search using impurity measure)
* 한번에 변수 한개씩(One variable at a time)

## 불순도

* 의사결정나무에서 어떠한 피쳐의 어떤 값을 기준으로 삼아야 할지를 정하는 기준.

* 가능한 모든 기준값에 대해 불순도를 계산한 후 이중 가장 낮은 불순도를 갖는 기준값으로 분류함.
  * 이때 사용되는 알고리즘은 탐욕 알고리즘(Greedy Search)이 활용됨.

### Gini impurity(지니 불순도)

* CART 나무에서 사용하는 불순도.
* ![수식2](https://camo.githubusercontent.com/baa25aec012470cc617ef37fc6f0779b0acd0a2da585857f33767bd1faee700a/687474703a2f2f63686172742e617069732e676f6f676c652e636f6d2f63686172743f6368743d74782663686c3d696d702874293d312d25354373756d5f2537426a3d3125374450253545325f6a)

* P는 노드 안의 각 확률 변수의 확률값.
* 불순도가 높다는것은 확률변수들이 치우치지 않고, 각 확률변수의 수가 같다는것을 의미.
* k=2일때 max=0.5가 되고, k=4일때 max=0.75가 됨.

## 향상도(Goodness of split)

* 이진분할같은 경우 노드가 두개로 나뉘게 되는데, 이때 각 노드의 가중평균값을 고려하게 됨.

* 분할하기 전 노드를 t, 분할후 노드를 t1, t2라고 했을때, 다음 식의 결과값을 탐욕 알고리즘으로 가장 높은 향상도를 갖는 기준값으로 분할함.

  * 향상도 = (노드 t의 불순도) - (t1과 t2노드의 불순도 가중평균)



## 용어 정리

### 분할 정복 알고리즘

* 문제를 나눌수 없을 때까지 나누어서 각각을 풀면서 다시 합병하여 문제의 답을 얻는 알고리즘

* 알고리즘 설계 요령

  * Divide : 문제가 분할이 가능한 경우, 2개 이상의 문제로 나눈다.
  * Conquer : 나누어진 문제가 여전히 분할이 가능하다면 Divide를 수행, 그렇지 않다면 문제를 푼다.
  * Combine : Conquer한 문제들을 통합하여 원래 문제의 답을 얻는다.

* 문제를 제대로 나눈다면 Conquer하는것은 쉽기 때문에 Divide를 제대로 하는것이 가장 중요하다.

* 분할정복 알고리즘은 재귀 알고리즘이 많이 사용되는데, 이 부분에서 분할정복 알고리즘의 효율성을 깎아내릴수 있다.

### 분할정복 응용

* 병합 정렬(Merge Sort)
  * 시간복잡도 O(nlogn), 공간복잡도 O(n)

  * Divide
  1. 정렬할 데이터 집합의 크기가 0 또는 1이면 이미 정렬된것으로 본다. 그렇지 않으면
  2. 데이터 집합을 반으로 나눈다.

  * Conquer & Combine

  3. 두 데이터 집합의 크기의 합 만큼의 크기를 가지는 빈 데이터 집합을 만든다.
  4. 두 데이터 집합의 첫번째 요소들을 비교하여 작은 요소를 빈 데이터 집합에 추가한다. 그리고 새 데이터 집합에 추가한 요소는 원래 데이터 집합에서 삭제한다.
  5. 원래 두 데이터 집합의 요소가 모두 삭제될때까지 4를 반복한다.

* 거듭제곱 계산의 개선
  * n거듭제곱은 자신을 n번 곱해야 하기 때문에 O(n)의 시간이 소요된다.

  * C^8은 C 자신을 8번 곱하는 것과 같지만, 동시에 C^2를 구한 뒤, 제곱을 두번 더 반복하면 세번의 연산으로 같은 값을 구할수 있다.

  * 따라서, 
  ![수식1](https://t1.daumcdn.net/cfile/tistory/2363794854B149E61A)
  로 나타낼수 있고,  
  이렇게 지수를 반으로 나눠가는 거듭제곱 알고리즘의 수행시간은 ![시간복잡도1](https://t1.daumcdn.net/cfile/tistory/22143A4F54B148B20B)이다.


### 탐욕 알고리즘

* 매순간 최적이라고 생각되는것을 선택해 나가는 방식으로 진행하여 최종적인 최적해에 도달하는 기법

* 주로 다음 사항을 만족하는 문제들에 자주 사용한다.
  * 앞의 선택이 이후 선택에 영향을 주지않을때
  * 문제 전체에 대한 최적해가 부분 문제에 대해서도 최적해가 될때



    
    


